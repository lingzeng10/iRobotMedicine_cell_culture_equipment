╔══════════════════════════════════════════════════════════════╗
║          Ollama AI Agent 使用說明                            ║
╚══════════════════════════════════════════════════════════════╝

【安裝步驟】

1. 安裝 Ollama
   - 訪問：https://ollama.ai/download
   - 下載 Windows 版本並安裝
   - 安裝完成後，Ollama 會自動在背景運行

2. 下載 AI 模型（可選，腳本會自動檢查）
   在命令提示字元中執行：
   ollama pull llama3.2
   
   或使用中文優化模型：
   ollama pull qwen2.5:7b

3. 啟動服務
   執行：start-with-ollama.bat
   
   腳本會自動：
   - 檢查 Ollama 是否已安裝
   - 檢查模型是否已下載（如果沒有會自動下載）
   - 啟動 Ollama 服務
   - 啟動後端服務（端口 5000）
   - 啟動前端服務（端口 3000）

【使用方式】

1. 等待前端服務啟動完成（約 30 秒）
   - 瀏覽器會自動開啟 http://localhost:3000
   - 如果沒有自動開啟，請手動訪問

2. 開啟 AI 助手
   - 在網頁右上角點擊 AI 圖示（🤖）
   - 會開啟 AI 助手對話框

3. 開始對話
   您可以詢問：
   
   📊 查詢資料庫：
   - 「查詢所有 AOI 工單」
   - 「列出進行中的生產目標」
   - 「顯示今天的排程」
   - 「找出所有完成的工單」
   
   📈 分析資料：
   - 「分析各類工單的完成率」
   - 「統計工單數量」
   - 「分析生產目標的狀態分布」
   
   💬 一般問題：
   - 「如何使用這個系統？」
   - 「如何新增生產目標？」

【功能說明】

AI Agent 可以：
1. 理解自然語言查詢
2. 自動分析用戶意圖
3. 查詢資料庫並返回結果
4. 進行資料統計和分析
5. 回答系統使用問題

【故障排除】

問題：AI 助手顯示「未連接」
解決：
1. 確認 Ollama 服務是否運行
   - 檢查是否有「Ollama 服務」視窗
   - 如果沒有，執行：ollama serve

2. 檢查 Ollama API 是否可訪問
   - 在瀏覽器訪問：http://localhost:11434/api/tags
   - 應該會看到模型列表

3. 重啟服務
   - 關閉所有服務視窗
   - 重新執行 start-with-ollama.bat

問題：AI 回應很慢
解決：
1. 確認模型已下載（執行：ollama list）
2. 如果使用較大的模型，回應會較慢
3. 可以嘗試使用較小的模型（如：llama3.2:1b）

問題：AI 無法理解查詢
解決：
1. 使用更明確的關鍵字（如：「查詢」、「列出」、「分析」）
2. 包含工單類型（如：「AOI 工單」、「換液工單」）
3. 包含狀態（如：「進行中」、「已完成」）

【環境變數設定（可選）】

如果需要自訂 Ollama 設定，可以在 server/.env 中添加：

OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

【推薦模型】

- llama3.2：平衡性能和速度（推薦）
- qwen2.5:7b：中文優化，適合中文對話
- llama3.2:1b：速度最快，但能力較弱
- llama3.2:3b：平衡選擇

下載模型：ollama pull <模型名稱>

【注意事項】

1. Ollama 服務需要持續運行才能使用 AI 功能
2. 首次使用時，模型下載可能需要幾分鐘
3. 較大的模型需要更多記憶體和運算時間
4. 建議至少 8GB RAM 才能流暢運行

